FinalProject CompLing
#call by
#python    Documents/tweets.py 
# when saved to Documents
import nltk  
from nltk.corpus import opinion_lexicon

poswords = set(opinion_lexicon.words("positive-words.txt")) 
negwords = set(opinion_lexicon.words("negative-words.txt")) 


f=open("paulryan.txt", "rU")
raw = f.read()
token= nltk.word_tokenize(raw)

f2 = open("pence.txt", "rU")
raw2 = f2.read()
token2 = nltk.word_tokenize(raw2)

#FIGURE OUT .LOWER

print(token)






#TRIED IN CLASS::::
>>> def finddemons():
...     emptylist = []
...     for red in raw:
...             if red.endswith("\n"):
...                     emptylist.append(red)
...             else:
...                     pass
...     return emptylist
... 
>>> finddemons()





def finddemons():
    for x in token:
        y = len(token)
        percpos = len([w for w in token if w in poswords ]) / y  ##if w in poswords and is lower?
        percneg = len([w for w in token if w in negwords ]) / y
        print(x, "pos:", round(percpos, 3), "neg:", round(percneg, 3))
        
finddemons()

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in finddemons
AttributeError: 'list' object has no attribute 'words'



def finddemons2():  
    for x in token2:
        y = token2.words(x)
        percpos = len([w for w in token2 if w in poswords ]) / len(y)
        percneg = len([w for w in token2 if w in negwords ]) / len(y)
        print(x, "pos:", round(percpos, 3), "neg:", round(percneg, 3))

finddemons()
finddemons2()



https://docs.python.org/3/library/tokenize.html
^^^^^^^^That has some awesome info about the tokenizing by line with this kind of file.

http://www.nltk.org/api/nltk.tokenize.html
^^^^^^^^^Good info on tweet tokenizing



#####THAT WORKSSSSSSS
>>> import nltk
>>> from nltk.corpus import opinion_lexicon
>>> poswords = set(opinion_lexicon.words("positive-words.txt")) 
>>> negwords = set(opinion_lexicon.words("negative-words.txt")) 
>>> f=open("paulryan.txt", "rU")
>>> raw = f.read()
>>> token= nltk.word_tokenize(raw)
>>> def finddemons():
...     for x in token:
...             percpos = len([w for w in token if w in poswords ]) / len(raw)
...             percneg = len([w for w in token if w in negwords ]) / len(raw)
...             print(x, "pos:", round(percpos, 3), "neg:", round(percneg, 3))
... 
>>> finddemons()

