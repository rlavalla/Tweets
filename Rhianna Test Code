FinalProject CompLing
#call by
#python    Documents/tweets.py 
# when saved to Documents
import nltk  
from nltk.corpus import opinion_lexicon
from nltk.tokenize.simple import (LineTokenizer, line_tokenize)

poswords = set(opinion_lexicon.words("positive-words.txt")) 
negwords = set(opinion_lexicon.words("negative-words.txt")) 


f=open("paulryan.txt", "rU")
raw = f.read()
token= nltk.line_tokenize(raw) ####CHANGED WORD TO LINE

f2 = open("pence.txt", "rU")
raw2 = f2.read()
token2 = nltk.line_tokenize(raw2)


print(token)

def finddemons():
    for x in token:
        y = token.words() .  #works on text type object (.words) OR tokenize each line in text
        percpos = len([w for w in token if w in poswords ]) / len(y)  ##if w in poswords and is lower?
        #percpos = len([w for w in token if w in poswords]) / len(raw)
        percneg = len([w for w in token if w in negwords ]) / len(y)
        print(x, "pos:", round(percpos, 3), "neg:", round(percneg, 3))
        
finddemons()

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in finddemons
AttributeError: 'list' object has no attribute 'words'



def finddemons2():  
    for x in token2:
        y = token2.words(x)
        percpos = len([w for w in token2 if w in poswords ]) / len(y)
        percneg = len([w for w in token2 if w in negwords ]) / len(y)
        print(x, "pos:", round(percpos, 3), "neg:", round(percneg, 3))

finddemons()
finddemons2()



https://docs.python.org/3/library/tokenize.html
^^^^^^^^That has some awesome info about the tokenizing by line with this kind of file.

http://www.nltk.org/api/nltk.tokenize.html
^^^^^^^^^Good info on tweet tokenizing

